



## 时空融合的目的

目前单一卫星传感器获取的影像数据无法同时兼顾高空间分辨率和高时 间分辨率。因此，国内外学者提出了许多遥感图像时空融合方法，来生成同时具 有高空间分辨率与高时间分辨率的遥感图像

其实可以看作是带更多约束条件的分辨率，其目的是为了获取连续的、高空间分辨率的影像，解决光学遥感影像在**时间分辨率和空间分辨率的矛盾**：现有的大多数卫星获取的影像在空间分辨率能做到较高，那么它的回访周期就很漫长。

- **通俗理解**

卫星带着相机对准地表拍摄，并绕着地球旋转，那如果卫星拍摄区域小，那拍出来的照片的就更加清晰（空间分辨率高），但是要拍完整个地球要花更多时间（时间分辨率低），如果卫星拍的面积更大，拍完整个地球一遍要花更少时间，但是照片更加模糊。



## 解决方法

那么如何才能获取高时空分辨率的影像呢？为什么要用时空融合技术来实现呢？

实际上，现有的办法主要有三种：

（1）多个搭载相同传感器的卫星组网，例如sentinel-2A和sentinel-2B双星，回访周期缩短一半；

（2）提高传感器性能和卫星的观测技术；

（3）将高时间分辨率影像和高空间分辨率影像进行融合来获取高时空分辨率影像。



## 基础原理

时空融合的基础原理如下图所示，其本质是结合两类影像的时空优势。

![img](image/资料收集/v2-60ca33f0bdcdfbd3fa76fb72ea5fc08d_720w.webp)

T1时相为我们能获取到两类影像的时相，T2时相是只有高时间分辨率影像的时相

上图只考虑了一对可用影像的情况，实际上很多算法会使用多对历史影像来提高融合的可靠性，如下图：

![img](image/资料收集/v2-8150de4ce4e2b14376d90c0015b6d602_720w.webp)

图片来自文献[https://doi.org/10.3390/rs10040527]



## STFDCNN

STFDCNN算法，该算法中引入了卷积神经网络来建模空间分辨率不一致的问题，来生成具有高时空的高分辨率图像







## GAN的提出和应用

GAN首先由Goodfellow等人提出[25]，然后，基于GAN的应用出现了爆炸式增长，例如图像生成[26]，超分辨率[27]，去噪[28]，修复[29]和图像到图像的翻译[30]，显示了其强大的建模能力。

[GAN详解](https://zhuanlan.zhihu.com/p/408766083)





## DCSTFN





## 略读论文

<span style='color:red'>红色字体</span>：表示疑问的地方

<span style="background-color: yellow;">黄色标记</span>：表示使用的方法

<span style=color:blue>蓝色字体</span>：表示解决的问题



###### Image De-raining Using a Conditional Generative Adversarial Network

摘要-恶劣的天气条件，如雨雪，对在这种条件下拍摄的图像的视觉质量产生不利影响，从而使它们无法进一步使用和共享。此外，这种退化的图像极大地影响了视觉系统的性能。因此，<span style=color:blue>解决单幅图像去雨问题</span>是非常重要的。然而，这个问题<span style='color:red'>固有的不适定性</span>带来了几个挑战。<span style="background-color: yellow;">我们试图利用最近引入的条件生成对抗网络(CGAN)的强大生成建模能力，**通过施加额外的约束**，即去雨图像必须与其对应的地面真实干净图像不可区分。来自GAN的对抗性损失提供了额外的规律性，并有助于实现更好的结果。除了提出一种去雨图像的新方法外，我们还**在生成器-鉴别器对中引入了一种新的精化损失函数和结构新颖性，以获得更好的结果**。Lost函数旨在减少Gans引入的伪影，并确保更好的视觉质量。生成器子网络是使用最近引入的密集连接网络来构建的，而鉴别器被设计为利用全局和局部信息来判断图像的真伪。</span>在此基础上，我们提出了一种新的单幅图像去雨方法--图像去雨条件生成对抗性网络(ID-CGAN)，该方法在目标函数中综合考虑了量化性能、视觉性能和判别性能。在合成图像和真实图像上的实验表明，该方法在量化和视觉性能方面都优于目前最先进的单幅图像去雨方法。此外，在FasterRCNN的目标检测数据集上的实验结果也证明了该方法在提高对降雨退化图像的检测性能方面的有效性。

[粗略讲解](https://blog.csdn.net/mmdbhs/article/details/122170935)













###### 对齐问题到底是什么？

特征对齐

[Re-ID中的特征对齐](https://zhuanlan.zhihu.com/p/126722559)







###### 知识蒸馏

[知识蒸馏方法总结（持续更新）](https://zhuanlan.zhihu.com/p/603748226)

[知识蒸馏（一）概述](https://zhuanlan.zhihu.com/p/581286422)

[知识蒸馏（Knowledge Distillation）简述（一）](https://zhuanlan.zhihu.com/p/81467832)

大概的理解

知识蒸馏，可以将一个网络的知识转移到另一个网络，两个网络可以是同构或者异构。做法是先训练一个teacher网络，然后使用这个teacher网络的输出和数据的真实标签去训练student网络。知识蒸馏，可以用来将网络从大网络转化成一个小网络，并保留接近于大网络的性能；也可以将多个网络的学到的知识转移到一个网络中，使得单个网络的性能接近emsemble的结果。







###### ViTGAN: Training GANs with Vision Transformers

中探索了使用 ViT 作为生成对抗网络 (GAN) 中图像合成任务的生成器和判别器的潜力。本文研究了在 GAN 背景下 ViT 与传统卷积架构的性能比较。

该论文的主要发现包括：

**基于 ViT 的 GAN 的性能与卷积 GAN 相当：**结果表明，利用 ViT 作为生成器和判别器的 ViTGAN 在图像合成质量方面与传统卷积 GAN（例如 StyleGAN2）具有相似的性能。

**改进的架构灵活性：**与卷积 GAN 相比，ViTGAN 提供了增强的架构灵活性。作者证明，ViTGAN 可以通过调整 Transformer 层的数量或 token 的数量来扩展，而不改变空间维度，从而更容易使模型适应不同的计算预算和问题规模。

**有效的迁移学习：**研究表明，预训练的 ViT 模型可以成功地作为 GAN 中的生成器进行微调，从而显著减少训练时间，同时保持竞争性能。这一发现强调了在图像合成任务中使用预先训练的 ViT 进行迁移学习的潜力。

**对输入变化的鲁棒性：**ViTGAN 对输入分布的变化表现出鲁棒性，如对损坏和分布外样本的实验所示。作者认为，ViT 中的注意力机制有助于这种鲁棒性，使模型能够有效地处理输入数据的变化。

总之，这项研究强调了在生成对抗网络中使用 ViT 来执行图像合成任务的优势。研究结果表明，基于 ViT 的 GAN 在图像质量、架构灵活性和迁移学习潜力方面优于传统的卷积 GAN。这些见解可以指导研究人员和从业者为图像合成应用选择合适的架构，并进一步探索 ViT 在该领域的潜力。









SAMFeat

**基于语义分组的弱监督对比学习**

然而，由于属于同一分组的两个像素并不意味着它们的描述符是最接近的一对，强制它们对齐将损害同一分组内像素的区分特性。因此，语义分组只能提供弱监督约束，作者通过在优化中设置边界来维护语义分组内的区分性。











本文研究的重点是近年来受到研究界越来越多关注的知识提炼问题。

大型深度神经网络已经取得了显着的成功，具有良好的性能，特别是在具有大规模数据的真实世界场景中，因为在考虑新数据时，过度参数化提高了泛化性能

在知识蒸馏中，一个小的学生模型通常由一个大的教师模型监督。其主要思想是学生模型模仿教师模型，以获得有竞争力的甚至是上级的表现。关键问题是如何将知识从大的教师模型转移到小的学生模型。基本上，知识蒸馏系统由三个关键组件组成：知识、蒸馏算法和师生架构

![image-20231214185948646](image/%E8%B5%84%E6%96%99%E6%94%B6%E9%9B%86/image-20231214185948646.png)
