STFGAN

摘要：由于技术和预算的限制，时空融合被认为是一种很有前途的方法来处理遥感图像的时间和空间分辨率之间的权衡。此外，生成对抗网络（GAN）已经在各种应用中显示出其能力。<span style="background-color: yellow;">提出了一种基于GAN的遥感图像时空融合方法（STFGAN），该方法采用两阶段框架，每一阶段都有一个端到端的图像融合GAN（IFGAN）。IFGAN包含一个生成器和一个在优化函数指导下相互竞争的搜索器。针对高时空分辨率Landsat影像与低时空分辨率MODIS影像之间存在的巨大空间分辨率差异，采用了特征级融合策略。</span>具体来说，对于生成器，我们首先对MODIS图像进行超分辨率处理，同时提取Landsat图像的高频特征。最后，我们综合了MODIS和Landsat图像的特征。STFGAN能够学习Landsat-MODIS图像对之间的端到端映射，并通过考虑所有波段来预测预测日期的Landsat-like图像。STFGAN显着提高了物候变化和土地覆盖类型变化的预测精度的帮助下，剩余块和两个先前的Landsat-MODIS图像对。为了检验所提出的STFGAN方法的性能，实验进行了三个代表Landsat-MODIS数据集。结果清楚地说明了所提出的方法的有效性。生成对抗网络（GAN），多光谱卫星数据，遥感，时空融合。







传统算法假设各土地覆被类型的比例在观测期间不发生变化的前提下建立的，没有考虑地球表面的人类活动，如干扰事件（如森林火灾）和城市土地利用的变化。

Huang和Song[32]提出了基于稀疏表示的时空反射融合模型（SPSTFM），这是第一个将**自然图像超分辨率中的字典对学习技术引入时空数据融合**的方法。





**复杂的异质区域（complex heterogeneous areas）**

在遥感图像时空融合中，复杂的异质区域通常指的是地表上存在多种不同类型、不同性质或不同状态的地物或覆盖物，并且它们可能在时空上表现出复杂的变化。这些区域可能包括各种土地覆盖类型、植被、土壤、水体、建筑物等。

异质性表现在不同区域之间的差异性，这种差异性可能由于地物的物理性质、生态环境、人类活动等多种因素引起。这使得对这些区域进行准确的遥感监测和分析变得更为具有挑战性。

在时空融合的背景下，通过整合来自不同传感器或不同时间点的遥感数据，可以提高对这些复杂异质区域的识别和监测的精度。例如，结合高空间分辨率的光学图像和高时间分辨率的雷达图像，可以更全面地了解异质区域的特征，并提供更详细、准确的信息。这种融合可以帮助遥感分析师和地学研究者更好地理解和监测地球表面的变化。



**不是端到端？**



首先，STFDCNN 和 StfNet 不是端到端的学习模型。预测阶段分为两部分--基于 CNN 的映射和重建，这增加了算法的复杂性。其次，每个波段都需要单独训练，这增加了参数量、内存使用量和训练时间。



端到端学习（End-to-End Learning）是指通过一个统一的、端到端的模型来完成一个完整的任务，而无需显式地拆分任务为多个独立的阶段或模块。在深度学习中，端到端网络是一种直接从输入数据到最终输出的模型，无需手动设计中间层或特征提取步骤。

传统的机器学习方法通常包含数据预处理、特征提取、模型训练和最终预测等多个步骤，每个步骤都可能需要手动设计和调整。端到端学习的思想是将这些步骤通过一个端到端的神经网络统一起来，让网络自动学习从输入到输出的映射关系，从而简化整个系统的设计和调试过程。

端到端学习的优势在于它可以更好地适应复杂的任务和数据，避免手动设计特征提取器的复杂性。然而，端到端学习的挑战之一是可能需要更大规模的数据和计算资源，以及对网络架构的仔细调整，以使其在实际任务中表现良好。

在深度学习中，许多应用，如语音识别、图像分类、机器翻译等，都可以通过端到端学习的方式进行建模，从而简化整个系统的设计。



**论文网络大致流程和优点**

在所提出的方法中，开发了一个两阶段框架来提高融合结果的准确性，其中每个阶段都包含一个端到端的图像融合GAN（IFGAN）。发生器和鉴别器以交替的方式进行优化，以使发生器尽可能有效地工作。具体来说，生成网络由三部分组成：1）MODIS图像的超分辨率；2） 陆地卫星图像的高频特征提取；和3）MODIS和陆地卫星特征图的融合。前两部分是通过残差块实现的。

1）据我们所知，这是第一个基于深度学习的**端到端**可训练网络，可用于解决时空融合问题。

2）为了从生成器中产生更好的时空融合结果，我们为生成器网络中的Landsat输入和MODIS输入开发了残差块结构。该方法可以捕捉到更多的纹理细节，并可以显著提高物候变化和土地覆盖类型变化预测的精度，借助于之前的两个Landsat-MODIS图像对。

3）将遥感图像的所有波段一起输入到网络中，而不是单独输入每个波段，这降低了时间和空间的消耗，特别是对于大范围的图像。





**超分辨率和时空融合之间存在的一些区别**

1）分辨率差异：一般来说，超分辨率的放大系数在2到4到8之间。然而，在时空融合中，两个数据源之间可能存在巨大的空间分辨率差距，通常在8到16之间(例如，空间分辨率为250/500米的陆地卫星和空间分辨率为30米的MODIS)。在这种情况下，直接将超分辨率方法应用于时空融合会导致结果的准确性较低。

2）空间差异：众所周知，遥感图像比自然图像包含更多的信息。这是因为遥感图像包含了更多的地理信息。复杂的特征类型和丰富的纹理特征增加了时空融合的难度。

3）时间差异：在单幅图像超分辨率下，只有一幅LR图像作为输入。相比之下，在时空融合中，有一对或两对先前日期的LR-HR图像对可用。利用图像对的空间细节信息作为补充信息源，可以在预测日提高LR图像的空间分辨率。

4）光谱差异：与自然图像不同，遥感图像有多个波段，只有红、绿、蓝三个波段。







**网络架构**

生成器网络可以分为三个部分：1）MODIS图像的超分辨率; 2）Landsat图像的高频特征提取; 3）MODIS和Landsat特征图的融合。

1）这16个残差块充分学习了MODIS图像的特征，包含物候变化信息和土地覆盖类型变化信息，为下一步的超分辨率奠定了基础

2）在短时间内，可以**假定**研究地点的土地覆盖没有显著变化，也就是说，L1和L3所包含的结构和纹理信息与L2相似。利用8个残差块提取Landsat级联图像的高频特征，如详细的纹理和结构，有助于地区边缘的恢复

在这两部分之后，将从FR图像和CR图像中提取的特征图通过ConcatLayer进行连接。低频信息来源于MODIS图像，高频信息来源于Landsat图像。通过结合这两个信息源，L2可以获得高质量的内容和结构细节。最后，利用卷积层降低输出张量维数，恢复预测的I2。

鉴别器用于区分真实图像(L2)和时空融合图像(I2)。

损失函数部分
。。。

![image-20231127191809063](C:\Users\hwh\AppData\Roaming\Typora\typora-user-images\image-20231127191809063.png)

<img src="C:\Users\hwh\AppData\Roaming\Typora\typora-user-images\image-20231127190014621.png" alt="image-20231127190014621" style="zoom:67%;" />





**深圳数据集**

文章使用了3个数据集包括，CIA，LGC和深圳数据集





**总结：**

文章借鉴超分辨率中的RSGAN网络，提出STFGAN，显着提高了物候变化和土地覆盖类型变化的预测精度。

网络架构的整体流程是:

输入：预测日期的粗MODIS图像和两个先前的Landsat-MODIS图像对

输出：预测日期相应的精细Landsat图像作为输出。

1）生成器阶段：

（1）对3张Modis图像上采样4倍，输入到网络，提取物候变化信息和土地覆盖类型变化信息，再进行下采样生成I_u。

（2）对2张Landset图像下采样输入网络，提取Landsat级联图像的高频特征，再与I_u连接输入到一个卷积中生成F_fake图像

2）鉴别器阶段

对真是图像和F_fake图像进行鉴别，根据鉴别结果来更新生成器，以生成更高质量的图像。

实验部分

数据集：3个数据集包括，CIA，LGC和深圳数据集

模型：使用了ESTARFM , SPSTFM 和STFDCNN模型进行计较和评估。

提供了评测指标的计算公式。







（学到的东西：

Landset提供高频特征，Modis图像提供地物变化信息。在GAN-STFM中好像只有前面的有用。

分阶段的生成器，所以生成器只要目的是 生成高质量的图像

）

